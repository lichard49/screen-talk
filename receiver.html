<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:300,300italic,700,700italic">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/milligram/1.3.0/milligram.css">
    <link rel="stylesheet" href="https://milligram.github.io/styles/main.css">

    <script src="js/fft.js"></script>
  </head>

  <body>
    <main class="wrapper">
      <nav class="navigation">
        <section class="container">
          <h1 class="title">Screen Talk ~ Receiver</h1>
        </section>
      </nav>

      <section class="container">
        <video id="camera" style="display: none;" autoplay playsinline></video>
        <button id="start-camera">Start camera</button>
        <p id="output"></p>
        <label for="recording"> Recording:</label>
        <input type="checkbox" id="recording"><br>
        <button id="clear-button" onclick="clearRecording();">Clear</button>
        <canvas id="camera-canvas"></canvas>
        <canvas id="fft-canvas"></canvas>
      </section>
    </main>

    <script type="text/javascript">
      const video = document.getElementById('camera');
      const button = document.getElementById('start-camera');

      button.addEventListener('click', event => {
        const videoConstraints = {
          facingMode: 'environment',
          franeRate: {
            exact: 60
          },
          width: 160,
          height: 120
        };
        const constraints = {
          video: videoConstraints,
          audio: false
        };
        navigator.mediaDevices
          .getUserMedia(constraints)
          .then(stream => {
            currentStream = stream;
            video.srcObject = stream;

            setupVideo();

            return navigator.mediaDevices.enumerateDevices();
          })
          .catch(error => {
            console.error(error);
          });
      });

      function setupVideo() {
        setInterval(drawFrame, 10);
      }

      // output canvas and context
      const camera_canvas = document.getElementById('camera-canvas');
      const camera_ctx = camera_canvas.getContext('2d');
      const fft_canvas = document.getElementById('fft-canvas');
      const fft_ctx = fft_canvas.getContext('2d');
      fft_ctx.translate(0, fft_canvas.height);   // move the origin
      fft_ctx.scale(1, -1);            // to the bottom left corner
      const output = document.getElementById('output');

      // FFT configuration
      const buffer = [];
      const fft_size = 64;
      const fft_h_scale = 8;
      const fft_v_scale = 1/20;
      const fft_low_bin = 5;
      const fft_high_bin = 10;
      let fft_threshold = 0;

      // recording controls
      const recording = document.getElementById('recording');

      function drawFrame() {
        if (camera_canvas.width != video.videoWidth) {
          camera_canvas.width = video.videoWidth;
          camera_canvas.height = video.videoHeight;
        }

        drawCamera(camera_ctx, camera_canvas, video);
        let frame = getCameraROI(camera_ctx);
        buffer.push(frame[0]);

        if (buffer.length >= fft_size) {
          // calculate FFT and show raw values
          let fft_mag = getFFT(buffer);
          updateFFTThreshold(fft_mag);

          // draw FFT and markers
          drawFFT(fft_ctx, fft_canvas, fft_mag);
          drawLine(fft_ctx, fft_low_bin * fft_h_scale, 0,
            fft_low_bin * fft_h_scale, fft_canvas.height);
          drawLine(fft_ctx, fft_high_bin * fft_h_scale, 0,
            fft_high_bin * fft_h_scale, fft_canvas.height);
          drawLine(fft_ctx, 0, fft_threshold * fft_v_scale,
            fft_mag.length*8, fft_threshold * fft_v_scale);

          if (recording.checked) {
            output.innerHTML += getFFTPeak(fft_mag,
              fft_low_bin, fft_high_bin) + ' ';
          }

          // slide window
          for (let i = fft_size/2-1; i >= 0; i--) {
            buffer.shift();
          }
        }
      }

      function drawCamera(context, canvas, frame) {
        context.drawImage(frame, 0, 0);
        context.beginPath();
        context.arc(canvas.width/2, canvas.height/2, 5, 0, 2 * Math.PI);
        context.strokeStyle = '#FF0000';
        context.lineWidth = 2;
        context.stroke();
      }

      function getCameraROI(context) {
        return context.getImageData(camera_canvas.width/2-1,
          camera_canvas.height/2, 1, 1).data;
      }

      function getFFT(signal) {
        let real = jsFFT.populateFullReal(fft_size, signal);
        let imag = jsFFT.makeComplex(real, fft_size);
        let freq = jsFFT.FFT(imag, fft_size, 1);
        let mag = jsFFT.Magnitude(freq, fft_size);

        return mag;
      }

      function updateFFTThreshold(fft) {
        fft_threshold = fft[0] * 0.0015;
      }

      function drawFFT(context, canvas, fft) {
        context.clearRect(0, 0, fft.length*8, canvas.height);
        context.beginPath();
        for (let i = fft.length - 1; i >= 0; i--) {
          context.lineTo(i*fft_h_scale, fft[i]*fft_v_scale);
        }
        context.strokeStyle = '#000000';
        context.lineWidth = 1;
        context.stroke();
      }

      function drawLine(context, x0, y0, x1, y1) {
        context.beginPath();
        context.lineTo(x0, y0);
        context.lineTo(x1, y1);
        context.strokeStyle = '#FF0000';
        context.lineWidth = 1;
        context.stroke();
      }

      function getFFTPeak(fft, low_bin, high_bin) {
        let low_bin_mag = fft[low_bin];
        let high_bin_mag = fft[high_bin];

        if (low_bin_mag > high_bin_mag) {
          if (low_bin_mag > fft_threshold) {
            return 1;
          }
        } else if (high_bin_mag > low_bin_mag) {
          if (high_bin_mag > fft_threshold) {
            return 2;
          }
        }

        return 0;
      }

      function clearRecording() {
        output.innerHTML = '';
      }
    </script>
  </body>
</html>